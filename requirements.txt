# Qwen Image Edit Offline Editor - Server Edition
# A6000 GPU (48GB VRAM x 8) Linux Server Requirements

# Core dependencies (버전 호환성 주의)
# torch와 torchvision은 함께 설치해야 합니다 (아래 Installation Instructions 참고)
diffusers>=0.30.0
transformers>=4.37.0
accelerate>=0.20.0

# Image processing
Pillow>=10.0.0

# HuggingFace
huggingface-hub>=0.20.0

# Progress bar
tqdm>=4.65.0

# Optional: For better performance
ninja  # For faster CUDA compilation
xformers  # Memory efficient attention (optional)

# Installation Instructions:
#
# ⚠️ 중요: torch와 torchvision을 먼저 설치해야 합니다!
#
# 1. PyTorch with CUDA (필수 - 먼저 설치):
#    CUDA 12.1 사용 시:
#      pip install torch==2.5.1 torchvision==0.20.1 --index-url https://download.pytorch.org/whl/cu121
#
#    CUDA 11.8 사용 시:
#      pip install torch==2.5.1 torchvision==0.20.1 --index-url https://download.pytorch.org/whl/cu118
#
#    ⚠️ torch와 torchvision 버전이 호환되어야 합니다!
#
# 2. Diffusers 최신 버전 (Qwen 모델 지원):
#    pip install git+https://github.com/huggingface/diffusers
#
# 3. 나머지 의존성:
#    pip install transformers>=4.37.0 accelerate>=0.20.0 Pillow>=10.0.0 tqdm>=4.65.0 huggingface-hub>=0.20.0
#
# 4. xformers (선택, 메모리 최적화):
#    pip install xformers
#
# 5. 설치 확인:
#    python -c "import torch; import torchvision; from diffusers import QwenImageEditPlusPipeline; print('✓ 설치 성공')"
#
# System Requirements:
# - OS: Linux (Ubuntu 20.04+, CentOS 8+ 권장)
# - CUDA: 11.8+ 또는 12.x
# - Driver: NVIDIA Driver 525+ (CUDA 12.x) 또는 470+ (CUDA 11.x)
# - GPU: NVIDIA A6000 (48GB VRAM) x 8
# - RAM: 256GB+ 권장
# - Storage: NVMe SSD 1TB+ (모델 저장 및 빠른 I/O)
